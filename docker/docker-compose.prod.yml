version: '3.7'

services:
  ohbug-ce:
    image: ohbug/ohbug-ce:latest
    restart: always
    env_file:
      - ../.env.production
    volumes:
      - /usr/src/app
      - ./nginx/certs:/etc/ssl/certs
      - ./nginx/conf.d:/etc/nginx/conf.d
    ports:
      - 6660:6660
      - 6666:6666
      - 80:80
      # - 443:443
    extra_hosts:
      - 'host.docker.internal:172.17.0.1'

  zookeeper:
    image: confluentinc/cp-zookeeper:5.5.1
    restart: always
    hostname: zookeeper
    ports:
      - '2181:2181'
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
  kafka1:
    image: confluentinc/cp-kafka:5.5.1
    restart: always
    hostname: kafka1
    ports:
      - '9092:9092'
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka1:19092,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: 'kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_FETCH_MAX_WAIT_MS: 100
      KAFKA_FETCH_MIN_BYTES: 1
    volumes:
      - ./temp/kafka1/data:/var/lib/kafka/data
    depends_on:
      - zookeeper
  kafka2:
    image: confluentinc/cp-kafka:5.5.1
    restart: always
    hostname: kafka2
    ports:
      - '9093:9093'
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka2:19093,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_BROKER_ID: 2
      KAFKA_LOG4J_LOGGERS: 'kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_FETCH_MAX_WAIT_MS: 100
      KAFKA_FETCH_MIN_BYTES: 1
    volumes:
      - ./temp/kafka2/data:/var/lib/kafka/data
    depends_on:
      - zookeeper

  elasticsearch:
    build:
      context: ./elasticsearch/
      args:
        ELK_VERSION: 7.6.2
    restart: always
    hostname: elasticsearch
    volumes:
      - type: bind
        source: ./elasticsearch/config/elasticsearch.yml
        target: /usr/share/elasticsearch/config/elasticsearch.yml
        read_only: true
      - type: volume
        source: elasticsearch
        target: /usr/share/elasticsearch/data
    ports:
      - '9200:9200'
      - '9300:9300'
    environment:
      ES_JAVA_OPTS: '-Xmx256m -Xms256m'
      ELASTIC_PASSWORD: changeme
      # Use single node discovery in order to disable production mode and avoid bootstrap checks
      # see https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html
      discovery.type: single-node
  logstash:
    build:
      context: ./logstash/
      args:
        ELK_VERSION: 7.6.2
    restart: always
    hostname: logstash
    volumes:
      - type: bind
        source: ./logstash/config/logstash.yml
        target: /usr/share/logstash/config/logstash.yml
        read_only: true
      - type: bind
        source: ./logstash/pipeline
        target: /usr/share/logstash/pipeline
        read_only: true
      - type: bind
        source: ./logstash/templates
        target: /usr/share/logstash/templates
        read_only: true
    ports:
      - '9600:9600'
    environment:
      LS_JAVA_OPTS: '-Xmx256m -Xms256m'
    depends_on:
      - elasticsearch

  postgres:
    image: postgres:12
    restart: always
    hostname: postgres
    ports:
      - '5432:5432'
    environment:
      POSTGRES_DB: ohbug
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ohbug_postgres_password
      PG_DATA: /var/lib/postgresql/data
    volumes:
      - pgdata:/var/lib/postgresql/data

  redis:
    image: redis:6.0.1
    restart: always
    ports:
      - '6379:6379'
    volumes:
      - ./temp/redis/redis.conf:/etc/redis/redis.conf
    command: redis-server /etc/redis/redis.conf

volumes:
  pgdata:
  elasticsearch:
